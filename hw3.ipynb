{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d774215",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install ISLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cc2da29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib.pyplot import subplots\n",
    "import sklearn.model_selection as skm\n",
    "from ISLP import load_data, confusion_table\n",
    "from ISLP.models import ModelSpec as MS\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "16e99f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4470, 16)\n",
      "Index(['ID', 'Name', 'Location', 'Year', 'Kilometers_Driven', 'Fuel_Type',\n",
      "       'Transmission', 'Owner_Type', 'Mileage', 'Engine', 'Power', 'Colour',\n",
      "       'Seats', 'No. of Doors', 'New_Price', 'Price'],\n",
      "      dtype='object')\n",
      "Number of unique names: 207\n",
      "(4470, 15)\n",
      "['Coimbatore', 'Kochi', 'Hyderabad', 'Kolkata', 'Bangalore', 'Delhi', 'Pune', 'Chennai', 'Mumbai', 'Ahmedabad', 'Jaipur', '\\\\N']\n",
      "Number of unique locations: 12\n",
      "(4470, 14)\n",
      "(4470, 13)\n"
     ]
    }
   ],
   "source": [
    "# load the training data train.csv\n",
    "train_data = pd.read_csv('train.csv')\n",
    "train_data.head()\n",
    "print(train_data.shape)\n",
    "print(train_data.columns)\n",
    "# Remove some features that are supposed to be not useful for prediction\n",
    "\n",
    "# Access the 'Name' column data\n",
    "name_column = train_data['Name']\n",
    "\n",
    "# check how many different names are there in the name column\n",
    "name_list = name_column.unique().tolist()\n",
    "print(f\"Number of unique names: {len(name_list)}\") #207 => too much, ignore name feature\n",
    "\n",
    "# drop the Name feature\n",
    "train_data = train_data.drop(columns=['Name'])\n",
    "print(train_data.shape)\n",
    "\n",
    "# check how many different locations are there in the Location column\n",
    "location_column = train_data['Location']\n",
    "location_list = location_column.unique().tolist()\n",
    "print(location_list)\n",
    "print(f\"Number of unique locations: {len(location_list)}\") \n",
    "train_data = train_data.drop(columns=['Location'])# =12, also drop location feature\n",
    "print(train_data.shape)\n",
    "\n",
    "# Drop the feature \"New-Price\" because there is not many data\n",
    "train_data = train_data.drop(columns=['New_Price'])\n",
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0258b535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4470, 13)\n",
      "51\n",
      "(4419, 13)\n"
     ]
    }
   ],
   "source": [
    "# clean the data\n",
    "# loop for all columns to remove rows with NaN values\n",
    "model = MS(train_data.columns, intercept=False)\n",
    "D = model.fit_transform(train_data)\n",
    "print(D.shape)\n",
    "nan_index = []\n",
    "for col in D.columns:\n",
    "    for i in range(D.shape[0]):\n",
    "        if D[col][i] == '\\\\N':\n",
    "            nan_index.append(i)\n",
    "nan_index = list(set(nan_index)) # remove duplicates\n",
    "print(len(nan_index))\n",
    "# remove the rows that have NaN in any column\n",
    "for idx in nan_index:\n",
    "    D = D.drop(index=idx)\n",
    "print(D.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393184df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_428576/3455394867.py:5: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  D['Year'][i] = 0.5 + (D['Year'][i]-D['Year'].min())/(D['Year'].max()-D['Year'].min())\n",
      "/tmp/ipykernel_428576/3455394867.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  D['Year'][i] = 0.5 + (D['Year'][i]-D['Year'].min())/(D['Year'].max()-D['Year'].min())\n",
      "/tmp/ipykernel_428576/3455394867.py:5: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '1.2142857142857144' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  D['Year'][i] = 0.5 + (D['Year'][i]-D['Year'].min())/(D['Year'].max()-D['Year'].min())\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "53",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/pandas/core/indexes/base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:2606\u001b[39m, in \u001b[36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:2630\u001b[39m, in \u001b[36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 53",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[82]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m D[\u001b[33m'\u001b[39m\u001b[33mYear\u001b[39m\u001b[33m'\u001b[39m] = pd.to_numeric(D[\u001b[33m'\u001b[39m\u001b[33mYear\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(D[\u001b[33m'\u001b[39m\u001b[33mYear\u001b[39m\u001b[33m'\u001b[39m])):\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mD\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mYear\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m != \u001b[32m0\u001b[39m: \u001b[38;5;66;03m# normalise data that is not 0\u001b[39;00m\n\u001b[32m      5\u001b[39m         D[\u001b[33m'\u001b[39m\u001b[33mYear\u001b[39m\u001b[33m'\u001b[39m][i] = \u001b[32m0.5\u001b[39m + (D[\u001b[33m'\u001b[39m\u001b[33mYear\u001b[39m\u001b[33m'\u001b[39m][i]-D[\u001b[33m'\u001b[39m\u001b[33mYear\u001b[39m\u001b[33m'\u001b[39m].min())/(D[\u001b[33m'\u001b[39m\u001b[33mYear\u001b[39m\u001b[33m'\u001b[39m].max()-D[\u001b[33m'\u001b[39m\u001b[33mYear\u001b[39m\u001b[33m'\u001b[39m].min())\n\u001b[32m      6\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/pandas/core/series.py:1133\u001b[39m, in \u001b[36mSeries.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   1130\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._values[key]\n\u001b[32m   1132\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[32m-> \u001b[39m\u001b[32m1133\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1135\u001b[39m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[32m   1136\u001b[39m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[32m   1137\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/pandas/core/series.py:1249\u001b[39m, in \u001b[36mSeries._get_value\u001b[39m\u001b[34m(self, label, takeable)\u001b[39m\n\u001b[32m   1246\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._values[label]\n\u001b[32m   1248\u001b[39m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1249\u001b[39m loc = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1251\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[32m   1252\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._values[loc]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/pandas/core/indexes/base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3815\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3816\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3817\u001b[39m     ):\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3824\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 53"
     ]
    }
   ],
   "source": [
    "# Preprocess the year data\n",
    "D['Year'] = pd.to_numeric(D['Year'])# covert to numeric\n",
    "for i in range(len(D['Year'])):\n",
    "    if D['Year'][i] != 0: # normalise data that is not 0\n",
    "        D['Year'][i] = 0.5 + (D['Year'][i]-D['Year'].min())/(D['Year'].max()-D['Year'].min())\n",
    "    else:\n",
    "        D['Year'][i] = 0\n",
    "print(D['Year'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7415abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle NaN in Kilometers_Driven column\n",
    "nan_index = []\n",
    "for i in range(D.shape[0]): # find nan in Kilo column\n",
    "    try:\n",
    "        float(D['Kilometers_Driven'][i]) \n",
    "    except:\n",
    "        D['Kilometers_Driven'][i] = '0'\n",
    "        \n",
    "        nan_index.append(i)\n",
    "print(nan_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "48bec3d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Handle NaN in Fuel_Type column\n",
    "nan_index = []\n",
    "for i in range(D.shape[0]): # find nan in Kilo column\n",
    "    try:\n",
    "        float(D['Fuel_Type'][i]) \n",
    "    except:       \n",
    "        nan_index.append(i)\n",
    "print(nan_index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
