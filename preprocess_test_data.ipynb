{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6d774215",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install ISLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "cc2da29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib.pyplot import subplots\n",
    "import sklearn.model_selection as skm\n",
    "from ISLP import load_data, confusion_table\n",
    "from ISLP.models import ModelSpec as MS\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from sklearn.tree import (DecisionTreeClassifier as DTC,\n",
    "                          DecisionTreeRegressor as DTR,\n",
    "                          plot_tree,\n",
    "                          export_text)\n",
    "from sklearn.metrics import (accuracy_score,\n",
    "                             log_loss)\n",
    "from sklearn.ensemble import \\\n",
    "     (RandomForestRegressor as RF,\n",
    "      GradientBoostingRegressor as GBR)\n",
    "from ISLP.bart import BART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "16e99f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1491, 15)\n",
      "Index(['ID', 'Name', 'Location', 'Year', 'Kilometers_Driven', 'Fuel_Type',\n",
      "       'Transmission', 'Owner_Type', 'Mileage', 'Engine', 'Power', 'Colour',\n",
      "       'Seats', 'No. of Doors', 'New_Price'],\n",
      "      dtype='object')\n",
      "Number of unique names: 161\n",
      "(1491, 14)\n",
      "['Pune', 'Chennai', '\\\\N', 'Mumbai', 'Coimbatore', 'Delhi', 'Bangalore', 'Kolkata', 'Jaipur', 'Ahmedabad', 'Hyderabad', 'Kochi']\n",
      "Number of unique locations: 12\n",
      "(1491, 13)\n",
      "(1491, 12)\n"
     ]
    }
   ],
   "source": [
    "# load the training data test.csv\n",
    "test_data = pd.read_csv('test.csv')\n",
    "test_data.head()\n",
    "print(test_data.shape)\n",
    "print(test_data.columns)\n",
    "# Remove some features that are supposed to be not useful for prediction\n",
    "\n",
    "# Access the 'Name' column data\n",
    "name_column = test_data['Name']\n",
    "\n",
    "# check how many different names are there in the name column\n",
    "name_list = name_column.unique().tolist()\n",
    "print(f\"Number of unique names: {len(name_list)}\") #207 => too much, ignore name feature\n",
    "\n",
    "# drop the Name feature\n",
    "test_data = test_data.drop(columns=['Name'])\n",
    "print(test_data.shape)\n",
    "\n",
    "# check how many different locations are there in the Location column\n",
    "location_column = test_data['Location']\n",
    "location_list = location_column.unique().tolist()\n",
    "print(location_list)\n",
    "print(f\"Number of unique locations: {len(location_list)}\") \n",
    "test_data = test_data.drop(columns=['Location'])# =12, also drop location feature\n",
    "print(test_data.shape)\n",
    "\n",
    "# Drop the feature \"New-Price\" because there is not many data\n",
    "test_data = test_data.drop(columns=['New_Price'])\n",
    "print(test_data.shape) #1491, 12 -> cannot drop more\n",
    "\n",
    "model = MS(test_data.columns, intercept=False)\n",
    "D = model.fit_transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "393184df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average year: 2013\n",
      "0.5 1.5\n",
      "(1491, 12)\n"
     ]
    }
   ],
   "source": [
    "# Preprocess the year data\n",
    "year_sum = 0\n",
    "count = 0\n",
    "for year in D['Year']:\n",
    "    try:\n",
    "        year = int(year)\n",
    "        year_sum += year\n",
    "        count += 1\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "# calculate the average year\n",
    "avg_year = year_sum // count\n",
    "print(\"Average year:\", avg_year)\n",
    "\n",
    "# replace the missing year with the average year\n",
    "for year in D['Year']:\n",
    "    try:\n",
    "        year = int(year)\n",
    "    except:\n",
    "        # assign the average year\n",
    "        year = avg_year\n",
    "        # set to D\n",
    "        D.loc[D['Year'] == year, 'Year'] = str(year)\n",
    "\n",
    "# convert D['Year'] to int\n",
    "D['Year'] = pd.to_numeric(D['Year'])\n",
    "#normalize to 0.5 to 1.5\n",
    "min_year = D['Year'].min()*np.ones(D.shape[0])\n",
    "max_year = D['Year'].max()*np.ones(D.shape[0])\n",
    "D['Year'] = 0.5*np.ones(D.shape[0]) + (D['Year'] - min_year) / (max_year - min_year)\n",
    "print(D['Year'].min(), D['Year'].max())\n",
    "\n",
    "#print(D['Year'])\n",
    "print(D.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a7415abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Kilometers_Driven: 57289\n",
      "1000.0 720000.0\n",
      "0       0.586787\n",
      "1       0.622392\n",
      "2       0.578288\n",
      "3       0.543115\n",
      "4       0.606096\n",
      "          ...   \n",
      "1486    0.609875\n",
      "1487    0.557719\n",
      "1488    0.550904\n",
      "1489    0.600139\n",
      "1490    0.518940\n",
      "Name: Kilometers_Driven, Length: 1491, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Preprocess the Kilometers_Driven data\n",
    "# first calculate the average km\n",
    "km_sum = 0\n",
    "km_count = 0\n",
    "\n",
    "# calculate the average year\n",
    "for km in D['Kilometers_Driven']:\n",
    "    try:\n",
    "        km = int(km)\n",
    "        km_sum += km\n",
    "        km_count += 1\n",
    "    except:\n",
    "        continue\n",
    "average_km = km_sum // km_count\n",
    "print(\"Average Kilometers_Driven:\", average_km)\n",
    "\n",
    "# replace the missing km with the average km\n",
    "for km in D['Kilometers_Driven']:\n",
    "    try:\n",
    "        km = int(km)\n",
    "    except:\n",
    "        # set to D\n",
    "        D.loc[D['Kilometers_Driven'] == km, 'Kilometers_Driven'] = str(average_km)\n",
    "\n",
    "D['Kilometers_Driven'] = pd.to_numeric(D['Kilometers_Driven'])# covert to numeric\n",
    "\n",
    "\n",
    "# normalize the Kilometers_Driven data to 0.5 to 1.5\n",
    "min_km = D['Kilometers_Driven'].min()*np.ones(D.shape[0])\n",
    "max_km = D['Kilometers_Driven'].max()*np.ones(D.shape[0])\n",
    "\n",
    "print(min_km[0], max_km[0])\n",
    "\n",
    "#normalize to 0.5 to 1.5\n",
    "D['Kilometers_Driven'] = 0.5*np.ones(D.shape[0]) + (D['Kilometers_Driven'] - min_km) / (max_km - min_km)\n",
    "print(D['Kilometers_Driven'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "48bec3d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Diesel', 'Petrol', 'CNG', 'LPG']\n",
      "Index(['ID', 'Year', 'Kilometers_Driven', 'Transmission', 'Owner_Type',\n",
      "       'Mileage', 'Engine', 'Power', 'Colour', 'Seats', 'No. of Doors',\n",
      "       'Fuel_Type_Diesel', 'Fuel_Type_Petrol', 'Fuel_Type_CNG',\n",
      "       'Fuel_Type_LPG'],\n",
      "      dtype='object')\n",
      "(1491, 15)\n"
     ]
    }
   ],
   "source": [
    "# Fuel type preprocessing\n",
    "fuel_types = D['Fuel_Type'].unique().tolist() # check how many different fuel types\n",
    "print(fuel_types)\n",
    "for fuel in fuel_types: # encode each fuel type into a separate binary feature\n",
    "    D[f'Fuel_Type_{fuel}'] = D['Fuel_Type'].apply(lambda x: 1 if x == fuel else 0)\n",
    "D = D.drop(columns=['Fuel_Type']) # drop the original Fuel_Type column\n",
    "print(D.columns) # print to check\n",
    "print(D.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "50bfcae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1491, 15)\n",
      "['Manual', 'Automatic', '\\\\N']\n",
      "Index(['ID', 'Year', 'Kilometers_Driven', 'Owner_Type', 'Mileage', 'Engine',\n",
      "       'Power', 'Colour', 'Seats', 'No. of Doors', 'Fuel_Type_Diesel',\n",
      "       'Fuel_Type_Petrol', 'Fuel_Type_CNG', 'Fuel_Type_LPG',\n",
      "       'Transmission_Manual', 'Transmission_Automatic', 'Transmission_\\N'],\n",
      "      dtype='object')\n",
      "0       1\n",
      "1       0\n",
      "2       0\n",
      "3       0\n",
      "4       1\n",
      "       ..\n",
      "1486    1\n",
      "1487    0\n",
      "1488    0\n",
      "1489    1\n",
      "1490    1\n",
      "Name: Transmission_Manual, Length: 1491, dtype: int64\n",
      "(1491, 17)\n"
     ]
    }
   ],
   "source": [
    "# Process the 'Transmission' column\n",
    "print(D.shape)\n",
    "transmission_types = D['Transmission'].unique().tolist() # check how many different transmission types\n",
    "print(transmission_types)\n",
    "for transmission in transmission_types: # encode each transmission type into a separate binary feature\n",
    "    D[f'Transmission_{transmission}'] = D['Transmission'].apply(lambda x: 1 if x == transmission else 0)\n",
    "D = D.drop(columns=['Transmission']) # drop the original Transmission column\n",
    "print(D.columns) # print to check\n",
    "print(D['Transmission_Manual']) # print to check\n",
    "print(D.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0867d1f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['First', 'Second', 'Third', '\\\\N', 'Fourth & Above']\n"
     ]
    }
   ],
   "source": [
    "#Process the 'Owner_Type' column\n",
    "owner_types = D['Owner_Type'].unique().tolist() # check how many different owner types\n",
    "print(owner_types)\n",
    "for owner in owner_types: # encode each owner type into a separate binary feature\n",
    "    D[f'Owner_Type_{owner}'] = D['Owner_Type'].apply(lambda x: 1 if x == owner else 0)\n",
    "D = D.drop(columns=['Owner_Type']) # drop the original Owner_Type column\n",
    "# print(D.columns) # print to check\n",
    "# print(D['Owner_Type_Second']) # print to check\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c7f6c038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        17.8 kmpl\n",
      "1       16.07 kmpl\n",
      "2        12.4 kmpl\n",
      "3       14.84 kmpl\n",
      "4        17.0 kmpl\n",
      "           ...    \n",
      "1486    13.93 kmpl\n",
      "1487    18.33 kmpl\n",
      "1488    16.55 kmpl\n",
      "1489    12.05 kmpl\n",
      "1490     18.6 kmpl\n",
      "Name: Mileage, Length: 1491, dtype: object\n",
      "Average Mileage: 18.104346076458743\n",
      "0       17.80\n",
      "1       16.07\n",
      "2       12.40\n",
      "3       14.84\n",
      "4       17.00\n",
      "        ...  \n",
      "1486    13.93\n",
      "1487    18.33\n",
      "1488    16.55\n",
      "1489    12.05\n",
      "1490    18.60\n",
      "Name: Mileage, Length: 1491, dtype: float64\n",
      "0.0 33.54\n",
      "0       1.030710\n",
      "1       0.979129\n",
      "2       0.869708\n",
      "3       0.942457\n",
      "4       1.006857\n",
      "          ...   \n",
      "1486    0.915325\n",
      "1487    1.046512\n",
      "1488    0.993441\n",
      "1489    0.859273\n",
      "1490    1.054562\n",
      "Name: Mileage, Length: 1491, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Preprocess Mileage\n",
    "print(D['Mileage'])\n",
    "D['Mileage'] = D['Mileage'].str.split(' ').str[0] # extract the numeric part\n",
    "\n",
    "# compute the average mileage\n",
    "mileage_sum = 0\n",
    "mileage_count = 0\n",
    "for mileage in D['Mileage']:\n",
    "    try:\n",
    "        mileage = float(mileage)\n",
    "        mileage_sum += mileage\n",
    "        mileage_count += 1\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "average_mileage = mileage_sum / mileage_count\n",
    "print(\"Average Mileage:\", average_mileage)\n",
    "\n",
    "# replace the missing mileage with the average mileage\n",
    "for mileage in D['Mileage']:\n",
    "    try:\n",
    "        mileage = float(mileage)\n",
    "    except:\n",
    "        # set to D\n",
    "        D.loc[D['Mileage'] == mileage, 'Mileage'] = str(average_mileage)\n",
    "\n",
    "D['Mileage'] = pd.to_numeric(D['Mileage'])# covert to numeric\n",
    "print(D['Mileage'])\n",
    "# normalize the Mileage data to 0.5 to 1.5\n",
    "min_mileage = D['Mileage'].min()*np.ones(D.shape[0])\n",
    "max_mileage = D['Mileage'].max()*np.ones(D.shape[0])\n",
    "print(min_mileage[0], max_mileage[0])\n",
    "#normalize to 0.5 to 1.5\n",
    "D['Mileage'] = 0.5*np.ones(D.shape[0]) + (D['Mileage'] - min_mileage) / (max_mileage - min_mileage)\n",
    "print(D['Mileage'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "069f9968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       1399 CC\n",
      "1       1995 CC\n",
      "2       2698 CC\n",
      "3       1598 CC\n",
      "4       1497 CC\n",
      "         ...   \n",
      "1486    2179 CC\n",
      "1487    1968 CC\n",
      "1488    1968 CC\n",
      "1489    2179 CC\n",
      "1490    1197 CC\n",
      "Name: Engine, Length: 1491, dtype: object\n",
      "Average Engine: 1635\n",
      "0       1399\n",
      "1       1995\n",
      "2       2698\n",
      "3       1598\n",
      "4       1497\n",
      "        ... \n",
      "1486    2179\n",
      "1487    1968\n",
      "1488    1968\n",
      "1489    2179\n",
      "1490    1197\n",
      "Name: Engine, Length: 1491, dtype: int64\n",
      "624.0 5461.0\n",
      "0       0.660223\n",
      "1       0.783440\n",
      "2       0.928778\n",
      "3       0.701364\n",
      "4       0.680484\n",
      "          ...   \n",
      "1486    0.821480\n",
      "1487    0.777858\n",
      "1488    0.777858\n",
      "1489    0.821480\n",
      "1490    0.618462\n",
      "Name: Engine, Length: 1491, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Process Engine\n",
    "print(D['Engine'])\n",
    "D['Engine'] = D['Engine'].str.split(' ').str[0] # extract the numeric part\n",
    "\n",
    "sum_engine = 0\n",
    "count_engine = 0\n",
    "for engine in D['Engine']:\n",
    "    try:\n",
    "        engine = int(engine)\n",
    "        sum_engine += engine\n",
    "        count_engine += 1\n",
    "    except:\n",
    "        continue\n",
    "average_engine = sum_engine // count_engine\n",
    "print(\"Average Engine:\", average_engine)\n",
    "# replace the missing engine with the average engine\n",
    "for engine in D['Engine']:\n",
    "    try:\n",
    "        engine = int(engine)\n",
    "    except:\n",
    "        # set to D\n",
    "        D.loc[D['Engine'] == engine, 'Engine'] = str(average_engine)\n",
    "\n",
    "D['Engine'] = pd.to_numeric(D['Engine'])# covert to numeric\n",
    "print(D['Engine'])\n",
    "# normalize the Engine data to 0.5 to 1.5\n",
    "min_engine = D['Engine'].min()*np.ones(D.shape[0])\n",
    "max_engine = D['Engine'].max()*np.ones(D.shape[0])\n",
    "print(min_engine[0], max_engine[0])\n",
    "#normalize to 0.5 to 1.5\n",
    "D['Engine'] = 0.5*np.ones(D.shape[0]) + (D['Engine'] - min_engine) / (max_engine - min_engine)\n",
    "print(D['Engine'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "dc2794cc",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can only use .str accessor with string values!",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[98]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Process Power\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m D[\u001b[33m'\u001b[39m\u001b[33mPower\u001b[39m\u001b[33m'\u001b[39m] = \u001b[43mD\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mPower\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstr\u001b[49m.split(\u001b[33m'\u001b[39m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m).str[\u001b[32m0\u001b[39m] \u001b[38;5;66;03m# extract the numeric part\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# calculate the average power\u001b[39;00m\n\u001b[32m      4\u001b[39m power_sum = \u001b[32m0\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/pandas/core/generic.py:6321\u001b[39m, in \u001b[36mNDFrame.__getattr__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   6314\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   6315\u001b[39m     name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._internal_names_set\n\u001b[32m   6316\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._metadata\n\u001b[32m   6317\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._accessors\n\u001b[32m   6318\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._info_axis._can_hold_identifiers_and_holds_name(name)\n\u001b[32m   6319\u001b[39m ):\n\u001b[32m   6320\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[name]\n\u001b[32m-> \u001b[39m\u001b[32m6321\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[43m.\u001b[49m\u001b[34;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/pandas/core/accessor.py:224\u001b[39m, in \u001b[36mCachedAccessor.__get__\u001b[39m\u001b[34m(self, obj, cls)\u001b[39m\n\u001b[32m    221\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m# we're accessing the attribute of the class, i.e., Dataset.geo\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._accessor\n\u001b[32m--> \u001b[39m\u001b[32m224\u001b[39m accessor_obj = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_accessor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    225\u001b[39m \u001b[38;5;66;03m# Replace the property with the accessor object. Inspired by:\u001b[39;00m\n\u001b[32m    226\u001b[39m \u001b[38;5;66;03m# https://www.pydanny.com/cached-property.html\u001b[39;00m\n\u001b[32m    227\u001b[39m \u001b[38;5;66;03m# We need to use object.__setattr__ because we overwrite __setattr__ on\u001b[39;00m\n\u001b[32m    228\u001b[39m \u001b[38;5;66;03m# NDFrame\u001b[39;00m\n\u001b[32m    229\u001b[39m \u001b[38;5;28mobject\u001b[39m.\u001b[34m__setattr__\u001b[39m(obj, \u001b[38;5;28mself\u001b[39m._name, accessor_obj)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/pandas/core/strings/accessor.py:194\u001b[39m, in \u001b[36mStringMethods.__init__\u001b[39m\u001b[34m(self, data)\u001b[39m\n\u001b[32m    191\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, data) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    192\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01marrays\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstring_\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StringDtype\n\u001b[32m--> \u001b[39m\u001b[32m194\u001b[39m     \u001b[38;5;28mself\u001b[39m._inferred_dtype = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    195\u001b[39m     \u001b[38;5;28mself\u001b[39m._is_categorical = \u001b[38;5;28misinstance\u001b[39m(data.dtype, CategoricalDtype)\n\u001b[32m    196\u001b[39m     \u001b[38;5;28mself\u001b[39m._is_string = \u001b[38;5;28misinstance\u001b[39m(data.dtype, StringDtype)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/pandas/core/strings/accessor.py:248\u001b[39m, in \u001b[36mStringMethods._validate\u001b[39m\u001b[34m(data)\u001b[39m\n\u001b[32m    245\u001b[39m inferred_dtype = lib.infer_dtype(values, skipna=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    247\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m inferred_dtype \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m allowed_types:\n\u001b[32m--> \u001b[39m\u001b[32m248\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCan only use .str accessor with string values!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m inferred_dtype\n",
      "\u001b[31mAttributeError\u001b[39m: Can only use .str accessor with string values!"
     ]
    }
   ],
   "source": [
    "# Process Power\n",
    "D['Power'] = D['Power'].str.split(' ').str[0] # extract the numeric part\n",
    "# calculate the average power\n",
    "power_sum = 0\n",
    "power_count = 0\n",
    "for power in D['Power']:\n",
    "    try:\n",
    "        power = float(power)\n",
    "        power_sum += power\n",
    "        power_count += 1\n",
    "    except:\n",
    "        continue\n",
    "average_power = power_sum / power_count\n",
    "print(\"Average Power:\", average_power)\n",
    "# replace the missing power with the average power\n",
    "for power in D['Power']:\n",
    "    try:\n",
    "        power = float(power)\n",
    "    except:\n",
    "        # set to D\n",
    "        D.loc[D['Power'] == power, 'Power'] = str(average_power)\n",
    "\n",
    "D['Power'] = pd.to_numeric(D['Power'])# covert to numeric\n",
    "print(D['Power'])\n",
    "# normalize the Power data to 0.5 to 1.5\n",
    "min_power = D['Power'].min()*np.ones(D.shape[0])\n",
    "max_power = D['Power'].max()*np.ones(D.shape[0])\n",
    "print(min_power[0], max_power[0])\n",
    "#normalize to 0.5 to 1.5\n",
    "D['Power'] = 0.5*np.ones(D.shape[0]) + (D['Power'] - min_power) / (max_power - min_power)\n",
    "print(D.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892c684d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process Colour column\n",
    "color_types = D['Colour'].unique().tolist() # check how many different color types\n",
    "print(color_types)\n",
    "for color in color_types: # encode each color type into a separate binary feature\n",
    "    D[f'Colour_{color}'] = D['Colour'].apply(lambda x: 1 if x == color else 0)\n",
    "D = D.drop(columns=['Colour']) # drop the original Colour column\n",
    "print(D.columns) # print to check\n",
    "print(D.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d22ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the Seats column\n",
    "# calculate the average seats\n",
    "seats_sum = 0\n",
    "seats_count = 0\n",
    "for seats in D['Seats']:\n",
    "    try:\n",
    "        seats = int(seats)\n",
    "        seats_sum += seats\n",
    "        seats_count += 1\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "average_seats = seats_sum / seats_count\n",
    "print(\"Average Seats:\", average_seats)\n",
    "# replace the missing seats with the average seats\n",
    "for seats in D['Seats']:\n",
    "    try:\n",
    "        seats = int(seats)\n",
    "    except:\n",
    "        # set to D\n",
    "        D.loc[D['Seats'] == seats, 'Seats'] = str(average_seats)\n",
    "\n",
    "\n",
    "D['Seats'] = pd.to_numeric(D['Seats'])# covert to numeric\n",
    "print(D['Seats'])\n",
    "# normalize the Seats data to 0.5 to 1.5\n",
    "min_seats = D['Seats'].min()*np.ones(D.shape[0])\n",
    "max_seats = D['Seats'].max()*np.ones(D.shape[0])\n",
    "print(min_seats[0], max_seats[0])\n",
    "#normalize to 0.5 to 1.5\n",
    "D['Seats'] = 0.5*np.ones(D.shape[0]) + (D['Seats'] - min_seats) / (max_seats - min_seats)\n",
    "print(D.shape)\n",
    "print(D['Seats'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85c86db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process No. of Doors column\n",
    "print(D['No. of Doors'])\n",
    "D['No. of Doors'] = pd.to_numeric(D['No. of Doors'])# covert to numeric\n",
    "print(D['No. of Doors'])\n",
    "# normalize the No. of Door data to 0.5 to 1.5\n",
    "min_doors = D['No. of Doors'].min()*np.ones(D.shape[0])\n",
    "max_doors = D['No. of Doors'].max()*np.ones(D.shape[0])\n",
    "print(min_doors[0], max_doors[0])\n",
    "#normalize to 0.5 to 1.5\n",
    "D['No. of Doors'] = 0.5*np.ones(D.shape[0]) + (D['No. of Doors'] - min_doors) / (max_doors - min_doors)\n",
    "\n",
    "print(D.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348cad45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we save processed D to a csv file\n",
    "D.to_csv('test_processed.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
